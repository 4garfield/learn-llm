{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad55e11f-2a6c-401e-8c41-eca5672d0cdb",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "Reference:\n",
    "* [PyMuPDF level 3 chunking](https://pymupdf.readthedocs.io/en/latest/rag.html#preparing-data-for-chunking)\n",
    "* [How to split text based on semantic similarity](https://python.langchain.com/docs/how_to/semantic-chunker/)\n",
    "* [Semantic Chunking for RAG](https://medium.com/the-ai-forum/semantic-chunking-for-rag-f4733025d5f5)\n",
    "* [5 Levels Of Text Splitting](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc5c4578-0e2c-4c96-b1b9-cf1f333dd6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_doc = \"./docs/2005.11401.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61edbc9a-bbdb-42b4-bc1c-69f528078d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "Retrieval-Augmented Generation for\n",
      "Knowledge-Intensive NLP Tasks\n",
      "Patrick Lewis†‡, Ethan Perez⋆,\n",
      "Aleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†, Naman Goyal†, Heinrich Küttler†,\n",
      "Mike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, Sebastian Riedel†‡, Douwe Kiela†\n",
      "†Facebook AI Research; ‡University College London; ⋆New York University;\n",
      "plewis@fb.com\n",
      "Abstract\n",
      "Large pre-trained language models have been shown to store factual knowledge\n",
      "in their parameters, and achieve state-of-the-art results when ﬁne-tuned on down-\n",
      "stream NLP tasks. However, their ability to access and precisely manipulate knowl-\n",
      "edge is still limited, and hence on knowledge-intensive tasks, their performance\n",
      "lags behind task-speciﬁc architectures. Additionally, providing provenance for their\n",
      "decisions and updating their world knowledge remain open research problems. Pre-\n",
      "trained models with a differentiable access mechanism to explicit non-parametric\n"
     ]
    }
   ],
   "source": [
    "# level 2: Recursive Character Text Splitting\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(\n",
    "    file_path = pdf_doc,\n",
    "    mode = \"page\",\n",
    "    extract_tables = \"markdown\"\n",
    ")\n",
    "documents = loader.load()\n",
    "\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "recursive_chunks = recursive_text_splitter.split_documents(documents)\n",
    "\n",
    "print(len(recursive_chunks))\n",
    "print(recursive_chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f0fbebc-1d6f-4217-946c-e851fe9e9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save chunks to check the result\n",
    "import pathlib\n",
    "\n",
    "for i in range(0, len(recursive_chunks)): \n",
    "    pathlib.Path(f\"./results/{i}.txt\").write_bytes(recursive_chunks[i].page_content.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5b0d7cf-1947-4cd2-abf5-1c2d57498289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./docs/2005.11401.pdf...\n",
      "]========================================] (19/19)\n",
      "104\n",
      "Large pre-trained language models have been shown to store factual knowledge\n",
      "in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance\n",
      "lags behind task-specific architectures. Additionally, providing provenance for their\n",
      "decisions and updating their world knowledge remain open research problems. Pretrained models with a differentiable access mechanism to explicit non-parametric\n",
      "memory have so far been only investigated for extractive downstream tasks. We\n",
      "explore a general-purpose fine-tuning recipe for retrieval-augmented generation\n",
      "(RAG) — models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric\n",
      "memory is a pre-trained seq2seq model and the non-parametric memory is a dense\n"
     ]
    }
   ],
   "source": [
    "# level 3: document chunking\n",
    "import pathlib\n",
    "import pymupdf4llm\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "\n",
    "md_text = pymupdf4llm.to_markdown(pdf_doc)\n",
    "md_splitter = MarkdownTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "md_chunks = md_splitter.create_documents([md_text])\n",
    "\n",
    "print(len(md_chunks))\n",
    "print(md_chunks[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f577bdc1-3421-47b3-ab03-8a7783f0914f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "Retrieval-Augmented Generation for\n",
      "Knowledge-Intensive NLP Tasks\n",
      "Patrick Lewis†‡, Ethan Perez⋆,\n",
      "Aleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†, Naman Goyal†, Heinrich Küttler†,\n",
      "Mike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, Sebastian Riedel†‡, Douwe Kiela†\n",
      "†Facebook AI Research; ‡University College London; ⋆New York University;\n",
      "plewis@fb.com\n",
      "Abstract\n",
      "Large pre-trained language models have been shown to store factual knowledge\n",
      "in their parameters, and achieve state-of-the-art results when ﬁne-tuned on down-\n",
      "stream NLP tasks. However, their ability to access and precisely manipulate knowl-\n",
      "edge is still limited, and hence on knowledge-intensive tasks, their performance\n",
      "lags behind task-speciﬁc architectures.\n"
     ]
    }
   ],
   "source": [
    "# level 4: semantic chunking\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name = \"BAAI/bge-m3\",\n",
    "    model_kwargs = {'device': 'cpu'},\n",
    ")\n",
    "\n",
    "semantic_splitter = SemanticChunker(\n",
    "    embedding,\n",
    "    breakpoint_threshold_type = \"percentile\"\n",
    ")\n",
    "\n",
    "semantic_chunks = semantic_splitter.create_documents([d.page_content for d in documents])\n",
    "\n",
    "print(len(semantic_chunks))\n",
    "print(semantic_chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3d0224-7fca-4b6b-a592-1d20bbc38e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
