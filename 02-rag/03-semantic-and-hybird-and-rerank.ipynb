{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e7711f4-c41d-4514-9e24-7007898eea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_milvus import Milvus, BM25BuiltInFunction\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d018b2-6421-4591-830c-cee41309f92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name = \"BAAI/bge-m3\",\n",
    "    model_kwargs = {'device': 'cpu'},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50a8f652-3073-4a4b-8383-2f0dda9e7582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_files(directory):\n",
    "    result = []\n",
    "    semantic_splitter = SemanticChunker(\n",
    "        embedding,\n",
    "        breakpoint_threshold_type = \"percentile\"\n",
    "    )\n",
    "    for file in os.listdir(directory):\n",
    "        loader = PyMuPDFLoader(\n",
    "            file_path = os.path.join(directory, file),\n",
    "            mode = \"page\",\n",
    "            extract_tables = \"markdown\",\n",
    "        )\n",
    "        documents = loader.load()\n",
    "        semantic_chunks = semantic_splitter.create_documents([d.page_content for d in documents])\n",
    "        result += semantic_chunks\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13d0942f-a157-41db-bc89-1904b7ca10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://milvus.io/docs/zh/milvus_hybrid_search_retriever.md\n",
    "vectorstore = Milvus.from_documents(\n",
    "    documents = load_pdf_files('./docs'),\n",
    "    embedding = embedding,\n",
    "    builtin_function = BM25BuiltInFunction(),\n",
    "    vector_field = [\"dense\", \"sparse\"],\n",
    "    connection_args={\n",
    "        \"uri\":  \"http://localhost:19530\",\n",
    "    },\n",
    "    consistency_level = \"Strong\",\n",
    "    drop_old = True,\n",
    ")\n",
    "\n",
    "rerank_model = HuggingFaceCrossEncoder(model_name = \"BAAI/bge-reranker-v2-m3\")\n",
    "retriever = ContextualCompressionRetriever(\n",
    "    base_compressor = CrossEncoderReranker(model = rerank_model, top_n = 5), \n",
    "    base_retriever = vectorstore.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a14ddd-7af4-49a0-ba18-b9af7ac1c02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_context(context_docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in context_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4b68931-f3d0-4d1c-ab37-d837f5c68747",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_prompt = \"\"\"\n",
    "Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n\\n\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"user\", formatted_prompt)],\n",
    ")\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"deepseek-r1:32b\",\n",
    "    temperature = 0.5\n",
    ")\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_context, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fac5272-eec2-4a2c-927c-b5211873f206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, I need to figure out what RAG stands for based on the provided context. Let me start by reading through the given information carefully. \\n\\nThe context mentions an \"OVERVIEW OF RAG\" and describes it as a typical application where a user asks ChatGPT a question about recent news. Since ChatGPT relies on pre-training data, it can\\'t provide up-to-date info. So, RAG bridges this gap by using external databases to get relevant information, which is then used along with the original question to help LLMs generate better answers.\\n\\nLooking further, there\\'s a section labeled A. Naive RAG, which talks about an early methodology that became popular after some initial work. It also mentions figures and tables related to RAG models generating more specific and accurate responses compared to BART models in certain tasks like Jeopardy question generation.\\n\\nThe context doesn\\'t explicitly define RAG, but based on the usage and surrounding information, it\\'s likely referring to a technique or framework used with language models. The acronym RAG might stand for something related to retrieval-augmented generation since the text discusses incorporating external knowledge into model responses.\\n\\nPutting this together, RAG seems to be a method that enhances LLMs by integrating retrieved information from external sources to improve answer quality and accuracy.\\n</think>\\n\\nRAG stands for Retrieval-Augmented Generation. It is a methodology that enhances language models by integrating information retrieved from external databases, allowing the models to provide more accurate and specific responses.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is RAG\"\n",
    "res = rag_chain.invoke(query)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e5290a-002d-4ec7-9a79-4485a0910623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
